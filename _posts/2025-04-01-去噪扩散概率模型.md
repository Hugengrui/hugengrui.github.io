---
title: 去噪扩散概率模型
date: 2024-04-05 10:00:00 +0800
categories: [深度学习, 生成模型]
tags: [AIGC, Diffusion]
---

<h2 align = "center">去噪扩散概率模型</h2>

<h4 align="center">摘&nbsp;要</h4>

​        扩散模型作为一种先进的生成模型，在过去几年里已经成为了机器学习领域的一个关键进展。我们展示了使用扩散概率模型进行高质量图像合成的结果，这是一类受到非平衡热力学考虑启发的潜变量模型。我们通过在根据扩散概率模型和带朗之万动力学的降噪分数匹配之间的新连接设计的加权变分界限上进行训练，获得了最佳结果。在无条件的CIFAR10数据集上，我们获得了9.46的Inception分数和3.17的最先进的FID分数。在图片大小为256x256的LSUN数据集上，我们获得了ProgressiveGAN相似的样本质量。

##### 关键词：无监督学习，马尔可夫链，扩散概率模型

#### 1. 引言

​	近期，各种类型的深度生成模型在各种数据中展示出了高质量的样本。扩散概率模型（简称“扩散模型”，DDPM）是使用变分推理训练的参数化马尔可夫链，经过有限时间产生与数据匹配的样本。该链的转移被学习用于逆转扩散过程，这是一个逐渐向数据添加噪声的马尔可夫链，噪声方向与采样相反，直到信号被破坏。扩散模型易于定义且训练高效，但据我们所知，迄今为止尚未证明它们能够生成高质量的样本。我们展示了扩散模型实际上能够生成高质量的样本，有时甚至优于其他类型生成模型的已发布结果。扩散概率模型在前向过程中向原图添加高斯噪音，经过一定步数后形成近似高斯分布的图，而反向过程是将该图一步步还原成原图。此做法改善了GANs不易收敛、不稳定的问题，扩散过程的逐步破坏结构能够更好地捕捉数据的复杂性。

#### 2.方法原理

​        扩散模型通过添加噪声，创建一个扩散过程。这个正向扩散过程是一个马尔可夫链，其中每一步都会向数据中添加一些噪声，使数据变得逐渐模糊。随后通过逆扩散过程，模型试图学习如何逆转正向扩散过程，从而去除在数据中逐步添加的噪声。逆扩散过程通过反向操作逐渐减少噪声，从而逐步还原数据的结构。以图片为例，模型通过加噪与去噪的手段学习训练数据的分布，产生尽可能符合训练数据分布的真实图片，所以它也成为后续文生图类扩散模型框架的基石。

​		模型的优化目标是学习训练数据的分布，产出尽可能符合训练数据分布的真实图片。设$P_\theta(x)$是模型所产生的图片的（概率）分布。其中$\theta$表示模型参数，这个分布是由模型决定的，$P_{data}(x)$表示训练数据（也可理解为真实世界）图片的（概率）分布。下标data表示这是一个自然世界客观存在的分布，与模型无关。用KL散度表示二者的相似程度，则优化目标可以表示为：
$$
argmin_\theta KL(P_{data}(x)||P_\theta(x)) = argmax_\theta \prod \limits_{i=1}^m P_\theta(x_i)
$$
即只要模型产生真实图片的概率越大，意味着两个分布越相似。

#### 3.算法实现说明

​	DDPM的训练过程主要分为前向过程与反向过程。向图片一步步加噪的过程是前向过程，最终得到的结果是一个极其近似高斯分布的噪声，可以看作是纯噪声；从一个纯噪声一步步去噪的过程是反向过程，最终得到一张原始图片。在反向过程中，我们用一个U-Net模型根据当前的输入预测噪声，再从输入与预测的噪声得到去噪后的图片。

##### 	3.1. 前向过程（扩散过程）

​	前向过程受到非平衡热力学的启发：分子从高浓度区域扩散至低浓度区域，直至整个系统处于平衡，这种不可逆的过程称为扩散。为使研究方便，我们将扩散看做马尔可夫过程，即将扩散开始到系统处于平衡态的时间分割为若干个时间步，每一步的状态都只与上一个状态有关。对于图片的前向过程也是同理，每次往图片上增加一些噪声，直至图片变为一个纯噪声为止。如下图所示：

![image-20231209111113283](https://cf.newbe.asia/2024/11/a856b759f4f6d4c2fc1b5029c86fc4c4.png)

​	设$N$为总步数，$x_0,x_1,x_2,\cdots,x_N$每一步产生的图片。其中$x_0$为原始图片，$x_N$为纯高斯噪声。

$\epsilon \sim N(0,I)$是每一步添加的高斯噪声，$q(x_t)$是在t步的概率分布，$\alpha_t$是t步的权重，则有：
$$
q(x_t|x_{t-1})=N(\sqrt{a_t}x_{t-1},(1-\alpha_t)I)
$$
由正态分布的封闭性，前向过程可重参数化为
$$
q(x_t|x_0)=N(\sqrt{\bar{\alpha_t}}x_0,\sqrt{1-\bar{\alpha_t}}I)
$$
其中，$\bar{\alpha_t}=\alpha_0\alpha_1\alpha_2\cdots \alpha_n$

##### 	3.2反向过程（去噪过程）

​	去噪过程是给定$x_t$,让模型将其还原为$x_{t-1}$,并最终还原到$x_0$的过程。在此过程中，模型从第T步开始，模型的输入为$x_t$与当前步骤$t$ 。模型中蕴含一个噪声预测器（U-Net），它会根据当前的输入预测出噪声，然后，将当前图片减去预测出来的噪声，就可以得到去噪后的图片。重复这个过程，直到还原出原始图片为止。由于模型每一步的去噪都用的是同一个模型，所以我们必须告诉模型，现在进行的是哪一步去噪。因此我们要引入当前步骤。步骤的表达方法类似于Transformer中的位置编码，将一个常数转换为一个向量，再和我们的输入图片进行相加。



##### 	3.3训练与采样

​	训练过程可表示如下：

​	![image-20231209212322204](https://cf.newbe.asia/2024/11/f7ae8d8243051b96564cac1076f41d4a.png)

- 从训练数据中，抽样出一条$x_0$（即$x_0\sim q(x_0)$)
- 随机抽样出一个步数$t$。（即$t\sim Uniform(\{1,\dots, T\})$）
- 随机抽样出一个噪声（即$\epsilon\sim N(0,1)$）
- 计算：$loss=\epsilon-\epsilon_\theta(\sqrt{\bar{\alpha_t}}x_0+\sqrt{1-\bar{\alpha_t}}\epsilon)$
- 计算梯度，更新模型$\epsilon_\theta$，重复上面过程，直至收敛。

​	采样过程可表示如下：

​	<img src="https://cf.newbe.asia/2024/11/65ddc436f976db5e05587edc219dd7f4.png" alt="image-20231209214554090" style="zoom:80%;" />

对于训练好的模型，我们从最后一个时刻$T$开始，传入一个纯噪声（或者是一张加了噪声的图片），逐步去噪。根据$x_t=\sqrt{\bar{\alpha_t}}x_0+\sqrt{1-\bar{\alpha_t}}\epsilon$，我们可以进一步推出$x_t$和$x_{t-1}$的关系。而$\sigma_tz$一项，则不是直接推导而来的，是我们为了增加推理中的随机性。

#### 4.实验

​	实验使用Cifar-10数据集，CIFAR-10（Canadian Institute for Advanced Research - 10）是一个广泛用于计算机视觉研究的图像数据集。该数据集由60000张32x32像素的彩色图像组成，涵盖了10个不同类别的物体，每个类别包含6000张图像。CIFAR-10是从CIFAR-100数据集中抽取出的一个子集，主要用于评估图像分类算法的性能。图像的分辨率相对较低，而且图像内容相对简单，使得CIFAR-10成为研究和开发计算机视觉任务的常见基准。

​	代码使用Pytorch 1.13.0作为框架，选用NVIDIA RTX 2080Ti进行CUDA加速并在Linux上运行Python程序。总的步数设定在1000步，Batch大小设定为128，迭代运行2500个Epoches，学习率设定在0.0002，完成一个epoch需70s，显存占用约5.5GB。

​	评估指标主要有Inception分数（IS）与FID，简要介绍如下：

​	Inception分数主要是为生成模型设计的，其值越高越好。其计算基于两个主要因素：模型生成的图像的多样性和每个图像的真实性。

- **多样性（Diversity）：** 使用一个预训练的卷积神经网络（通常是Inception网络）来提取生成的图像的特征。通过计算这些特征的概率分布，评估生成图像的多样性。多样性越高，分布越均匀，Inception分数就越高。

- **真实性（真实度）：** 对于每张生成的图像，通过Inception网络计算其在数据集上的概率分布。然后，计算生成图像的概率分布与数据集上真实图像的分布之间的KL散度（Kullback-Leibler Divergence）。真实性越高，KL散度越低，Inception分数就越高。

​	FID（Fréchet Inception Distance）是一种用于评估生成模型性能的指标，该指标结合了图像生成模型的多样性和真实性，并在一定程度上解决了一些其他评估指标的不足，FID越低，表示生成图像越接近真实图像。FID的优势在于，它对生成图像的多样性和真实性都有一定程度的敏感性，而且与人眼评价更为一致。较低的FID通常与更高质量、更真实的生成图像相关联。

​	实验结果如下：

​	![image-20231210075520070](https://cf.newbe.asia/2024/11/c8c9744b2214134c881ae6a91ef6d494.png)

​	可以看到，此方法在无条件的CIFAR10数据集上获得了9.46的Inception分数和3.17的最先进的FID分数。这里的Conditional表示生成模型受一定的约束，显然有约束IS与FID更高。NLL表示负对数似然，该指标越低，表示生成的数据与真实数据越接近。

​	下图是扩散模型生成效果展示：

![image-20231210100016024](https://cf.newbe.asia/2024/11/e0da2fdfa7ce757f6dd49508bc4daf75.png)

​	最左侧是$x_T$的状态，可以看到是近似高斯分布的噪声；最右侧是产生的图片，可以看到是逼真的图片。

#### 5.总结

​	本文使用扩散模型生成了高质量的图片样本，其创新之处在于引入了逐步去噪的思想，并且提供了一种对深度生成模型的新视角。它能通过迭代的正向扩散过程逐渐破坏数据分布中的结构，然后学习一个逆扩散过程以恢复数据中的结构。这种能力使得模型能够学习并理解数据中的复杂关系和模式，这是智能体现的一个方面。另外，扩散模型在推理方面能力出众，它可以根据学习到的模式，从近似高斯分布的噪声中推理出逼真的图片。

#### 参考文献

1. Ho J, Jain A, Abbeel P. Denoising diffusion probabilistic models[J]. Advances in neural information processing systems, 2020, 33: 6840-6851.
2. Kingma D P, Welling M. Auto-encoding variational bayes[J]. arXiv preprint arXiv:1312.6114, 2013.
3. [Insight/Diffusion/code at main · sagizty/Insight (github.com)](https://github.com/sagizty/Insight/tree/main/Diffusion/code)（代码来源）
4. Krizhevsky A, Hinton G. Learning multiple layers of features from tiny images[J]. 2009.（Cifar-10数据集）



